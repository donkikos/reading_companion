{
  "project": "Epub AI Reader",
  "branchName": "ralph/ingestion-v2",
  "description": "V2 Ingestion (Qdrant Chunk Indexing) - index EPUBs into chunked Qdrant payloads for spoiler-safe retrieval.",
  "userStories": [
    {
      "id": "US-001",
      "title": "Build deterministic sentence stream",
      "description": "As a reader, I want my uploaded book parsed into a stable sentence stream so indexing is consistent.",
      "acceptanceCriteria": [
        "Parse the EPUB into an ordered list of sentences S0..SN.",
        "Sentence IDs are monotonic and contiguous for each book.",
        "Run `ruff format` on changed Python files (line length 100)",
        "Run `ruff check .` and ensure it passes",
        "Add or update tests for this change",
        "Tests pass",
        "Run `pytest` and ensure it passes",
        "Typecheck/lint passes"
      ],
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-002",
      "title": "Create fixed-window chunks",
      "description": "As a reader, I want my book chunked consistently so retrieval quality is reliable.",
      "acceptanceCriteria": [
        "Create chunks using a fixed window of 8 sentences with overlap of 2.",
        "Each chunk covers the ordered sentence-id interval `[pos_start..pos_end]`.",
        "For each chunk, `sentences[k]` maps to `sid = pos_start + k`.",
        "Run `ruff format` on changed Python files (line length 100)",
        "Run `ruff check .` and ensure it passes",
        "Add or update tests for this change",
        "Tests pass",
        "Run `pytest` and ensure it passes",
        "Typecheck/lint passes"
      ],
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-003",
      "title": "Store chunk payloads in Qdrant",
      "description": "As a reader, I want my uploaded book indexed in Qdrant so spoiler-safe retrieval can use it.",
      "acceptanceCriteria": [
        "Store payload fields: `book_id`, `chapter_index`, `pos_start`, `pos_end`, `sentences`, `text`.",
        "Chunk embeddings are computed from the full chunk `text`.",
        "Qdrant points are written for each chunk of the current book.",
        "Run `ruff format` on changed Python files (line length 100)",
        "Run `ruff check .` and ensure it passes",
        "Add or update tests for this change",
        "Tests pass",
        "Run `pytest` and ensure it passes",
        "Typecheck/lint passes"
      ],
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-004",
      "title": "Replace chunks on re-upload",
      "description": "As a reader, I want re-uploading a book to replace old indexes so answers stay consistent.",
      "acceptanceCriteria": [
        "Re-ingestion deletes or replaces all prior chunks for the same `book_id`.",
        "No duplicate chunks remain after re-ingest.",
        "Run `ruff format` on changed Python files (line length 100)",
        "Run `ruff check .` and ensure it passes",
        "Add or update tests for this change",
        "Tests pass",
        "Run `pytest` and ensure it passes",
        "Typecheck/lint passes"
      ],
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-005",
      "title": "Track ingestion progress",
      "description": "As a reader, I want to see ingestion progress so I know when the book is ready.",
      "acceptanceCriteria": [
        "Progress is tracked as a best-effort percentage during ingestion.",
        "Progress is based on sentences processed out of total.",
        "Run `ruff format` on changed Python files (line length 100)",
        "Run `ruff check .` and ensure it passes",
        "Add or update tests for this change",
        "Tests pass",
        "Run `pytest` and ensure it passes",
        "Typecheck/lint passes"
      ],
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-006",
      "title": "Fail clearly if Qdrant is unavailable",
      "description": "As a reader, I want a clear failure when indexing cannot run so I can retry later.",
      "acceptanceCriteria": [
        "Ingestion fails with an explicit error when Qdrant cannot be reached.",
        "Partial ingestion is not marked as successful.",
        "Run `ruff format` on changed Python files (line length 100)",
        "Run `ruff check .` and ensure it passes",
        "Add or update tests for this change",
        "Tests pass",
        "Run `pytest` and ensure it passes",
        "Typecheck/lint passes"
      ],
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-007",
      "title": "Verify ingestion via API",
      "description": "As a developer, I want an API endpoint to verify Qdrant ingestion so I can confirm indexing without relying on retrieval.",
      "acceptanceCriteria": [
        "Provide an API endpoint that accepts `book_id` and verifies Qdrant ingestion for that book.",
        "The endpoint recomputes expected chunk count from the sentence stream and chunking params.",
        "The endpoint queries Qdrant by `book_id` and confirms the stored count matches expected.",
        "The endpoint validates payload fields and `pos_start`/`pos_end` monotonicity on a sample of chunks.",
        "The endpoint returns a clear pass/fail response with details on mismatches.",
        "If Qdrant is unavailable, the endpoint returns an explicit error.",
        "Restart the app server after implementing this story before verifying the endpoint.",
        "Run `ruff format` on changed Python files (line length 100)",
        "Run `ruff check .` and ensure it passes",
        "Add or update tests for this change",
        "Tests pass",
        "Run `pytest` and ensure it passes",
        "Typecheck/lint passes"
      ],
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-008",
      "title": "Single command to launch app + Qdrant",
      "description": "As a developer, I want a single `docker compose` command to start the app and Qdrant so ingestion can run without manual service setup.",
      "acceptanceCriteria": [
        "Provide one `docker compose` command that starts the FastAPI app and Qdrant.",
        "The command performs a health check that confirms the app responds and Qdrant is reachable.",
        "The command exits cleanly and stops both services.",
        "Restart the app server after implementing this story before running health checks.",
        "Run `ruff format` on changed Python files (line length 100)",
        "Run `ruff check .` and ensure it passes",
        "Add or update tests for this change",
        "Tests pass",
        "Run `pytest` and ensure it passes",
        "Typecheck/lint passes"
      ],
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-009",
      "title": "Add EPUB fixture for automated ingestion tests",
      "description": "As a developer, I want a stable EPUB fixture so ingestion tests can run deterministically.",
      "acceptanceCriteria": [
        "Add a fixture EPUB at `tests/fixtures/minimal.epub` with multiple chapters and paragraphs.",
        "Tests can ingest the fixture and verify Qdrant chunk counts using the verification API.",
        "Restart the app server after implementing this story before running the ingestion tests.",
        "The fixture stays ASCII-only and stable across runs.",
        "Run `ruff format` on changed Python files (line length 100)",
        "Run `ruff check .` and ensure it passes",
        "Add or update tests for this change",
        "Tests pass",
        "Run `pytest` and ensure it passes",
        "Typecheck/lint passes"
      ],
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-010",
      "title": "Delete a book with confirmation",
      "description": "As a reader, I want to delete a book with confirmation so I can remove it safely.",
      "acceptanceCriteria": [
        "Provide a delete action in the library UI that opens a confirmation dialog.",
        "Confirming delete removes the book file and all stored data (SQLite metadata, reading state, chapters, Chroma docs, Qdrant chunks).",
        "Cancelling delete leaves the book untouched.",
        "The library UI updates to remove the deleted book without a full reload.",
        "Restart the app server after implementing this story before verifying the UI.",
        "Run `ruff format` on changed Python files (line length 100)",
        "Run `ruff check .` and ensure it passes",
        "Add or update tests for this change",
        "Tests pass",
        "Run `pytest` and ensure it passes",
        "Typecheck/lint passes",
        "Verify in browser using MCP"
      ],
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-011",
      "title": "End-to-end ingestion progress in the UI",
      "description": "As a reader, I want clear progress updates across all ingestion stages so I know what is happening.",
      "acceptanceCriteria": [
        "Uploading a book shows progress messages and percentage updates in the library UI.",
        "The UI surfaces stage transitions (hashing, parsing, chunking, embedding, Qdrant upsert, metadata save).",
        "The progress percentage reflects the full ingestion pipeline, not only sentence streaming.",
        "The task status reaches \"completed\" only after all storage steps finish.",
        "Errors during ingestion surface a clear error message in the UI.",
        "Restart the app server after implementing this story before verifying the UI.",
        "Verify in browser using MCP.",
        "Run `ruff format` on changed Python files (line length 100)",
        "Run `ruff check .` and ensure it passes",
        "Add or update tests for this change",
        "Tests pass",
        "Run `pytest` and ensure it passes",
        "Typecheck/lint passes"
      ],
      "passes": false,
      "notes": "",
      "priority": "medium"
    },
    {
      "id": "US-012",
      "title": "Configure embedding provider for ingestion",
      "description": "As a developer, I want ingestion to use a configurable Ollama embedding service so we can improve retrieval quality without changing APIs.",
      "acceptanceCriteria": [
        "Embeddings are generated by calling Ollama `/api/embed` during ingestion.",
        "The embedding model name and base URL are configurable (default model: `BAAI/bge-base-en-v1.5`).",
        "Optional embedding dimensions are configurable (when supported by Ollama).",
        "If the embedding service is unavailable, ingestion fails with a clear error.",
        "Ollama runs as a docker compose service and uses a volume for model storage.",
        "Run `ruff format` on changed Python files (line length 100)",
        "Run `ruff check .` and ensure it passes",
        "Add or update tests for this change",
        "Tests pass",
        "Run `pytest` and ensure it passes",
        "Typecheck/lint passes"
      ],
      "passes": true,
      "notes": "",
      "priority": "high"
    },
    {
      "id": "US-013",
      "title": "Persist embedding metadata",
      "description": "As a developer, I want ingestion to record embedding metadata so retrieval can detect mismatches.",
      "acceptanceCriteria": [
        "The ingestion pipeline records the embedding model name and dimensions used.",
        "The ingestion pipeline documents that model changes require reindexing.",
        "Run `ruff format` on changed Python files (line length 100)",
        "Run `ruff check .` and ensure it passes",
        "Add or update tests for this change",
        "Tests pass",
        "Run `pytest` and ensure it passes",
        "Typecheck/lint passes"
      ],
      "passes": false,
      "notes": "",
      "priority": "medium"
    },
    {
      "id": "US-014",
      "title": "Use Ollama embeddings for Qdrant vectors",
      "description": "As a reader, I want Qdrant vectors to reflect semantic embeddings so retrieval quality is meaningful.",
      "acceptanceCriteria": [
        "Qdrant vectors are generated from Ollama embeddings of the full chunk text (not hash placeholders).",
        "Run an end-to-end ingestion using a live Ollama model and confirm embeddings are stored in Qdrant.",
        "Run `ruff format` on changed Python files (line length 100)",
        "Run `ruff check .` and ensure it passes",
        "Add or update tests for this change",
        "Tests pass",
        "Run `pytest` and ensure it passes",
        "Typecheck/lint passes"
      ],
      "passes": false,
      "notes": "",
      "priority": "high"
    },
    {
      "id": "US-015",
      "title": "Remove Chroma ingestion",
      "description": "As a developer, I want to remove Chroma writes so ingestion only targets Qdrant and SQLite.",
      "acceptanceCriteria": [
        "Ingestion no longer writes documents or metadata to Chroma.",
        "Removal is documented and tests are updated accordingly.",
        "Run `ruff format` on changed Python files (line length 100)",
        "Run `ruff check .` and ensure it passes",
        "Add or update tests for this change",
        "Tests pass",
        "Run `pytest` and ensure it passes",
        "Typecheck/lint passes"
      ],
      "passes": false,
      "notes": "",
      "priority": "low"
    },
    {
      "id": "US-016",
      "title": "Log ingestion timing metrics",
      "description": "As a developer, I want ingestion timing metrics so we can validate performance on CPU-only Macs.",
      "acceptanceCriteria": [
        "Logs include total ingestion time.",
        "Logs include time spent generating embeddings.",
        "Logs include time spent upserting to Qdrant.",
        "Logs include chunks processed and chunks/sec.",
        "Run `ruff format` on changed Python files (line length 100)",
        "Run `ruff check .` and ensure it passes",
        "Add or update tests for this change",
        "Tests pass",
        "Run `pytest` and ensure it passes",
        "Typecheck/lint passes"
      ],
      "passes": false,
      "notes": "",
      "priority": "low"
    }
  ]
}
