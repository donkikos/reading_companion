{
  "project": "Epub AI Reader",
  "branchName": "ralph/retrieval-v2",
  "description": "V2 Retrieval (Spoiler-Safe Qdrant Query) - implement spoiler-safe retrieval using TEI embeddings and Qdrant",
  "userStories": [
    {
      "id": "US-001",
      "title": "Configure TEI embedding provider",
      "description": "As a developer, I want embeddings generated by a configurable TEI service so retrieval quality can improve without changing APIs.",
      "acceptanceCriteria": [
        "Embeddings are generated by calling TEI /embed",
        "Embedding model name and base URL are configurable (defaults: TEI_MODEL=BAAI/bge-base-en-v1.5, TEI_BASE_URL=http://tei:80 in docker compose)",
        "TEI batch size and timeout are configurable (TEI_BATCH_SIZE default 8, TEI_TIMEOUT default 30)",
        "Retrieval fails with a clear error when the embedding service is unavailable (HTTP 503)",
        "TEI runs as a docker compose service and uses a volume for model storage",
        "Typecheck passes",
        "Tests pass"
      ],
      "priority": "high",
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-002",
      "title": "Generate query embeddings via TEI",
      "description": "As a reader, I want my query embedded via TEI so Qdrant returns semantically relevant chunks.",
      "acceptanceCriteria": [
        "Retrieval generates a query embedding using TEI /embed with the query string",
        "Embedding model matches ingestion",
        "Reject empty or whitespace-only queries with a clear error message (HTTP 400)",
        "Typecheck passes",
        "Tests pass"
      ],
      "priority": "high",
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-003",
      "title": "Query Qdrant for the current book with spoiler-safe filter",
      "description": "As a reader, I want the assistant to query Qdrant for my current book so answers use the right context.",
      "acceptanceCriteria": [
        "MCP reads user_pos from the persisted reading state before querying Qdrant",
        "Qdrant queries include spoiler-safe filter: pos_end <= user_pos (inclusive)",
        "Results are restricted to the current book_id",
        "MCP provides a list_books tool that returns structured JSON with book_id, title, and author so the agent can choose the correct book_id",
        "list_books response schema: {\"books\":[{\"book_id\":\"string\",\"title\":\"string\",\"author\":\"string\"}]}",
        "book_id is the canonical book identifier (same value used in Qdrant payloads and SQLite book hash)",
        "user_pos = 0 means the book was just added and the user has not started reading",
        "If reading state is missing or user_pos is null/invalid, retrieval fails with a clear error (HTTP 400)",
        "Typecheck passes",
        "Tests pass"
      ],
      "priority": "high",
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-004",
      "title": "Truncate sentence-based context at the spoiler boundary",
      "description": "As a reader, I want answers to never include sentences beyond my reading position.",
      "acceptanceCriteria": [
        "Sentence-based context iterates sentences and computes sid = pos_start + k (k is zero-based; sentence IDs start at 0)",
        "Context stops including sentences when sid > user_pos (include sid == user_pos)",
        "Only safe sentences are rejoined for final context",
        "Semantic search results rely on spoiler-safe Qdrant filter without extra truncation",
        "Typecheck passes",
        "Tests pass"
      ],
      "priority": "medium",
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-005",
      "title": "Deduplicate overlapping sentence context",
      "description": "As a reader, I want sentence-based context without repeated sentences so answers are clear.",
      "acceptanceCriteria": [
        "Overlapping sentences across chunks are removed from sentence-based context (dedupe by sid)",
        "Final context preserves original sentence order",
        "Typecheck passes",
        "Tests pass"
      ],
      "priority": "medium",
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-006",
      "title": "Return top-k relevant chunks",
      "description": "As a reader, I want responses limited to the most relevant chunks so answers are efficient and focused.",
      "acceptanceCriteria": [
        "Default retrieval returns top-k 20 chunks",
        "MCP retrieval tool accepts a k argument (max 256); if omitted, default to 20",
        "k controls the number of semantic-search chunks returned when a query is provided; when no query is provided, k controls the number of sentences returned",
        "Queries use dense vector search without reranking",
        "Typecheck passes",
        "Tests pass"
      ],
      "priority": "low",
      "passes": false,
      "notes": ""
    }
  ]
}
